{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "from torch import nn, optim\n",
    "from torch.nn import Linear, ReLU\n",
    "from torch.utils.data import DataLoader, Dataset\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self, layer_sizes: List[int]):\n",
    "        \"\"\"\n",
    "        The first layer size is the input dimension, and the last layer size is the output dimension.\n",
    "        :param layer_sizes:\n",
    "        \"\"\"\n",
    "        super(DNN, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        for i in range(0, len(layer_sizes) - 1):\n",
    "            self.layers.append(Linear(in_features=layer_sizes[i],\n",
    "                                      out_features=layer_sizes[i + 1]))\n",
    "            self.layers.append(ReLU())\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        for layer in self.layers:\n",
    "            # print(f'Layer {layer} with input size {x.size()}')\n",
    "            x = layer(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('x_train_transformed.pkl', 'rb') as f:\n",
    "    X_train = pickle.load(f)\n",
    "\n",
    "with open('x_test_transformed.pkl', 'rb') as f:\n",
    "    X_test = pickle.load(f)\n",
    "\n",
    "with open('y_train.pkl', 'rb') as f:\n",
    "    Y_train = pickle.load(f)\n",
    "\n",
    "with open('y_test.pkl', 'rb') as f:\n",
    "    Y_test = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "scipy.sparse._csr.csr_matrix"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<1x755851 sparse matrix of type '<class 'numpy.float64'>'\n\twith 52 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.getrow(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class SparseDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset class for scipy sparse matrix\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data: Union[np.ndarray, csr_matrix],\n",
    "                 targets: Union[np.ndarray, csr_matrix]):\n",
    "        # Transform data coo_matrix to csr_matrix for indexing\n",
    "        # if type(data) == coo_matrix:\n",
    "        #     self.data = data.tocsr()\n",
    "        # else:\n",
    "        self.data = data\n",
    "        self.datatype = type(data)\n",
    "\n",
    "        # Transform targets coo_matrix to csr_matrix for indexing\n",
    "        # if type(targets) == coo_matrix:\n",
    "        #     self.targets = targets.tocsr()\n",
    "        # else:\n",
    "        self.targets = targets\n",
    "        self.targettype = type(targets)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        # return self.data[index], self.targets[index]\n",
    "        x = self.data.getrow(index) if self.datatype == csr_matrix else self.data[index]\n",
    "        y = self.targets.getrow(index) if self.targettype == csr_matrix else self.targets[index]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    SparseDataset(data=X_train, targets=Y_train),\n",
    "    batch_size=128,\n",
    "    shuffle=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "755851"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def train_model(model, train: Tuple[csr_matrix, np.ndarray], validation: Tuple[csr_matrix, np.ndarray],\n",
    "                batch_size: int, epochs: int):\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    X_train, Y_train = train\n",
    "    n_samples = X_train.shape[0]\n",
    "    n_batches = math.ceil(n_samples * 1.0 / batch_size)\n",
    "    display = tqdm.trange(epochs)\n",
    "    validation_losses = []\n",
    "    for _ in display:\n",
    "        permutation = np.random.permutation(n_samples)\n",
    "\n",
    "        # train in this epoch\n",
    "        for batch_n in range(n_batches):\n",
    "            batch_indices = permutation[batch_n * batch_size:\n",
    "                                        min((batch_n + 1) * batch_size, len(permutation))]\n",
    "            batch_x = torch.as_tensor(X_train[batch_indices].todense(), dtype=torch.float32)\n",
    "            batch_y = torch.as_tensor(Y_train[batch_indices], dtype=torch.float32)\n",
    "\n",
    "            predictions = model(batch_x)\n",
    "            loss = nn.MSELoss()(predictions, batch_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        validation_loss = evaluate_model(model=model, dataset=validation)\n",
    "        validation_losses.append(validation_loss)\n",
    "        display.set_description(f'Validation loss: {validation_loss:.5}')\n",
    "\n",
    "        # stats, accuracy, loss_stat = evaluate_model(model=model, dataset=train)\n",
    "        # train_stats.append((stats, accuracy))\n",
    "        # train_losses.append(loss_stat)\n",
    "\n",
    "    # return validation_stats, validation_losses, train_stats, train_losses\n",
    "    return validation_losses\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataset: Tuple[csr_matrix, np.ndarray]) -> float:\n",
    "    X, Y = dataset\n",
    "    X_tens, Y_tens = torch.as_tensor(X.todense(), dtype=torch.float32), torch.as_tensor(Y, dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        raw_pred = model(X_tens)\n",
    "        predictions = np.array(torch.argmax(raw_pred, dim=1))\n",
    "\n",
    "    loss = torch.nn.MSELoss()(predictions, Y_tens)\n",
    "    return loss.item()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "model = DNN(layer_sizes=[256, 256, 1])\n",
    "train_model(model=model, train=(X_train, Y_train    ), validation=(X_test, Y_test), batch_size=128, epochs=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omg\n"
     ]
    }
   ],
   "source": [
    "print('omg')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m n_epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m100\u001B[39m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_epochs):\n\u001B[0;32m----> 3\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mi: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdataloader[i]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "for i in range(n_epochs):\n",
    "    print(f'i: {dataloader[i]}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sparse matrix length is ambiguous; use getnnz() or shape[0]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [10]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DataLoader, TensorDataset\n\u001B[1;32m      3\u001B[0m data \u001B[38;5;241m=\u001B[39m DataLoader(\n\u001B[0;32m----> 4\u001B[0m     TensorDataset(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m)\u001B[49m, torch\u001B[38;5;241m.\u001B[39mas_tensor(Y_train)),\n\u001B[1;32m      5\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m,\n\u001B[1;32m      6\u001B[0m     shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m      7\u001B[0m )\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ds/lib/python3.9/site-packages/scipy/sparse/_base.py:345\u001B[0m, in \u001B[0;36mspmatrix.__len__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    344\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__len__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 345\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse matrix length is ambiguous; use getnnz()\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    346\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m or shape[0]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: sparse matrix length is ambiguous; use getnnz() or shape[0]"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "data = DataLoader(\n",
    "    TensorDataset(torch.as_tensor(X_train.todense()), torch.as_tensor(Y_train)),\n",
    "    batch_size=128,\n",
    "    shuffle=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "coo = X_train.tocoo()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 1e+03 ns, total: 8 µs\n",
      "Wall time: 11.9 µs\n"
     ]
    }
   ],
   "source": [
    "% % time\n",
    "values = X_train.data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 215 ms, sys: 261 ms, total: 477 ms\n",
      "Wall time: 557 ms\n"
     ]
    }
   ],
   "source": [
    "% % time\n",
    "indices = np.vstack((coo.row, coo.col))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 242 µs, sys: 672 µs, total: 914 µs\n",
      "Wall time: 932 µs\n"
     ]
    }
   ],
   "source": [
    "% % time\n",
    "# i = torch.LongTensor(indices)\n",
    "i = torch.as_tensor(indices, dtype=torch.int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "% % time\n",
    "# v = torch.FloatTensor(values)\n",
    "v = torch.as_tensor(values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "coo = X_train.tocoo()\n",
    "values = X_train.data\n",
    "\n",
    "indices = np.vstack((coo.row, coo.col))\n",
    "\n",
    "i = torch.as_tensor(indices, dtype=torch.int)\n",
    "v = torch.as_tensor(values)\n",
    "shape = coo.shape\n",
    "\n",
    "X_train_tens = torch.sparse.FloatTensor(i, v, torch.Size(shape)).to_dense()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train.row"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omg\n"
     ]
    }
   ],
   "source": [
    "print('omg')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
